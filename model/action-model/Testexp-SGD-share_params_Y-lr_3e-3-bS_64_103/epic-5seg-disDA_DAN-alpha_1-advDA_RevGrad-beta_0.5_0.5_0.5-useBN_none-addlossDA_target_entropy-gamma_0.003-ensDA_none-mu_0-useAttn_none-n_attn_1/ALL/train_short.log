Train: [1][0/61], lr: 0.00300	Time 2.596 (2.596)	Data 0.745 (0.745)	Prec@1 17.188 (17.188)	Prec@1 6.250 (6.250)	Prec@1 0.000 (0.000)	Prec@5 73.438 (73.438)	Prec@5 56.250 (56.250)	Prec@5 46.875 (46.875)	Loss 4.3954 (4.3954)   loss_verb 2.0786   loss_noun 2.0799	alpha 1.000  loss_d 0.2331	beta 0.008, 0.008, 0.008  loss_a 2.0775	gamma 0.003000  loss_e_verb 2.0794 loss_e_noun 2.0794	
Train: [2][0/61], lr: 0.00300	Time 0.570 (0.570)	Data 0.439 (0.439)	Prec@1 65.625 (65.625)	Prec@1 0.000 (0.000)	Prec@1 0.000 (0.000)	Prec@5 96.875 (96.875)	Prec@5 45.312 (45.312)	Prec@5 43.750 (43.750)	Loss 3.4954 (3.4954)   loss_verb 1.2084   loss_noun 2.2414	alpha 1.000  loss_d 0.2392	beta 0.017, 0.017, 0.017  loss_a 2.0432	gamma 0.003000  loss_e_verb 1.5421 loss_e_noun 2.0021	
Train: [3][0/61], lr: 0.00300	Time 0.560 (0.560)	Data 0.429 (0.429)	Prec@1 96.875 (96.875)	Prec@1 18.750 (18.750)	Prec@1 18.750 (18.750)	Prec@5 98.438 (98.438)	Prec@5 90.625 (90.625)	Prec@5 89.062 (89.062)	Loss 2.5320 (2.5320)   loss_verb 0.2979   loss_noun 1.8694	alpha 1.000  loss_d 0.2083	beta 0.025, 0.025, 0.025  loss_a 2.0234	gamma 0.003000  loss_e_verb 0.7692 loss_e_noun 1.9745	
Train: [4][0/61], lr: 0.00300	Time 0.548 (0.548)	Data 0.435 (0.435)	Prec@1 93.750 (93.750)	Prec@1 31.250 (31.250)	Prec@1 28.125 (28.125)	Prec@5 100.000 (100.000)	Prec@5 95.312 (95.312)	Prec@5 95.312 (95.312)	Loss 2.4328 (2.4328)   loss_verb 0.2492   loss_noun 1.7950	alpha 1.000  loss_d 0.1692	beta 0.033, 0.033, 0.033  loss_a 2.0129	gamma 0.003000  loss_e_verb 0.5046 loss_e_noun 2.0180	
Train: [5][0/61], lr: 0.00300	Time 0.566 (0.566)	Data 0.448 (0.448)	Prec@1 92.188 (92.188)	Prec@1 26.562 (26.562)	Prec@1 23.438 (23.438)	Prec@5 98.438 (98.438)	Prec@5 82.812 (82.812)	Prec@5 81.250 (81.250)	Loss 2.3656 (2.3656)   loss_verb 0.2047   loss_noun 1.9822	alpha 1.000  loss_d 0.1526	beta 0.042, 0.042, 0.042  loss_a 2.0069	gamma 0.003000  loss_e_verb 0.4895 loss_e_noun 2.0364	
Train: [6][0/61], lr: 0.00300	Time 0.559 (0.559)	Data 0.398 (0.398)	Prec@1 95.312 (95.312)	Prec@1 43.750 (43.750)	Prec@1 42.188 (42.188)	Prec@5 100.000 (100.000)	Prec@5 92.188 (92.188)	Prec@5 92.188 (92.188)	Loss 2.3305 (2.3305)   loss_verb 0.1766   loss_noun 1.8712	alpha 1.000  loss_d 0.1491	beta 0.050, 0.050, 0.050  loss_a 2.0035	gamma 0.003000  loss_e_verb 0.4022 loss_e_noun 2.0356	
Train: [7][0/61], lr: 0.00300	Time 0.489 (0.489)	Data 0.407 (0.407)	Prec@1 96.875 (96.875)	Prec@1 51.562 (51.562)	Prec@1 48.438 (48.438)	Prec@5 100.000 (100.000)	Prec@5 98.438 (98.438)	Prec@5 98.438 (98.438)	Loss 2.3321 (2.3321)   loss_verb 0.1136   loss_noun 1.7332	alpha 1.000  loss_d 0.2143	beta 0.058, 0.058, 0.058  loss_a 2.0029	gamma 0.003000  loss_e_verb 0.4012 loss_e_noun 1.9992	
Train: [8][0/61], lr: 0.00300	Time 0.555 (0.555)	Data 0.445 (0.445)	Prec@1 100.000 (100.000)	Prec@1 29.688 (29.688)	Prec@1 29.688 (29.688)	Prec@5 100.000 (100.000)	Prec@5 98.438 (98.438)	Prec@5 98.438 (98.438)	Loss 2.2558 (2.2558)   loss_verb 0.0810   loss_noun 1.7828	alpha 1.000  loss_d 0.1730	beta 0.066, 0.066, 0.066  loss_a 2.0007	gamma 0.003000  loss_e_verb 0.3731 loss_e_noun 2.0031	
Train: [9][0/61], lr: 0.00300	Time 0.534 (0.534)	Data 0.425 (0.425)	Prec@1 100.000 (100.000)	Prec@1 31.250 (31.250)	Prec@1 31.250 (31.250)	Prec@5 100.000 (100.000)	Prec@5 95.312 (95.312)	Prec@5 95.312 (95.312)	Loss 2.4107 (2.4107)   loss_verb 0.0829   loss_noun 1.7914	alpha 1.000  loss_d 0.3284	beta 0.074, 0.074, 0.074  loss_a 1.9983	gamma 0.003000  loss_e_verb 0.3621 loss_e_noun 2.0027	
Train: [10][0/61], lr: 0.00030	Time 0.530 (0.530)	Data 0.434 (0.434)	Prec@1 98.438 (98.438)	Prec@1 15.625 (15.625)	Prec@1 15.625 (15.625)	Prec@5 100.000 (100.000)	Prec@5 95.312 (95.312)	Prec@5 95.312 (95.312)	Loss 2.2179 (2.2179)   loss_verb 0.0726   loss_noun 1.8361	alpha 1.000  loss_d 0.1442	beta 0.083, 0.083, 0.083  loss_a 2.0004	gamma 0.003000  loss_e_verb 0.2290 loss_e_noun 2.0115	
Train: [11][0/61], lr: 0.00030	Time 0.527 (0.527)	Data 0.410 (0.410)	Prec@1 98.438 (98.438)	Prec@1 40.625 (40.625)	Prec@1 39.062 (39.062)	Prec@5 100.000 (100.000)	Prec@5 98.438 (98.438)	Prec@5 98.438 (98.438)	Loss 2.3128 (2.3128)   loss_verb 0.0565   loss_noun 1.7850	alpha 1.000  loss_d 0.2488	beta 0.091, 0.091, 0.091  loss_a 2.0064	gamma 0.003000  loss_e_verb 0.3597 loss_e_noun 2.0248	
Train: [12][0/61], lr: 0.00030	Time 0.525 (0.525)	Data 0.410 (0.410)	Prec@1 100.000 (100.000)	Prec@1 29.688 (29.688)	Prec@1 29.688 (29.688)	Prec@5 100.000 (100.000)	Prec@5 100.000 (100.000)	Prec@5 100.000 (100.000)	Loss 2.3886 (2.3886)   loss_verb 0.1058   loss_noun 1.8629	alpha 1.000  loss_d 0.2828	beta 0.099, 0.099, 0.099  loss_a 1.9992	gamma 0.003000  loss_e_verb 0.2967 loss_e_noun 2.0198	
Train: [13][0/61], lr: 0.00030	Time 0.526 (0.526)	Data 0.397 (0.397)	Prec@1 100.000 (100.000)	Prec@1 26.562 (26.562)	Prec@1 26.562 (26.562)	Prec@5 100.000 (100.000)	Prec@5 93.750 (93.750)	Prec@5 93.750 (93.750)	Loss 2.2443 (2.2443)   loss_verb 0.0837   loss_noun 1.9002	alpha 1.000  loss_d 0.1585	beta 0.107, 0.107, 0.107  loss_a 2.0011	gamma 0.003000  loss_e_verb 0.3330 loss_e_noun 2.0250	
Train: [14][0/61], lr: 0.00030	Time 0.539 (0.539)	Data 0.442 (0.442)	Prec@1 100.000 (100.000)	Prec@1 17.188 (17.188)	Prec@1 17.188 (17.188)	Prec@5 100.000 (100.000)	Prec@5 96.875 (96.875)	Prec@5 96.875 (96.875)	Loss 2.3473 (2.3473)   loss_verb 0.0611   loss_noun 1.9096	alpha 1.000  loss_d 0.2861	beta 0.115, 0.115, 0.115  loss_a 1.9994	gamma 0.003000  loss_e_verb 0.2645 loss_e_noun 2.0303	
Train: [15][0/61], lr: 0.00030	Time 0.560 (0.560)	Data 0.444 (0.444)	Prec@1 100.000 (100.000)	Prec@1 26.562 (26.562)	Prec@1 26.562 (26.562)	Prec@5 100.000 (100.000)	Prec@5 95.312 (95.312)	Prec@5 95.312 (95.312)	Loss 2.2457 (2.2457)   loss_verb 0.0621   loss_noun 1.8701	alpha 1.000  loss_d 0.1781	beta 0.122, 0.122, 0.122  loss_a 2.0047	gamma 0.003000  loss_e_verb 0.2598 loss_e_noun 2.0361	
Train: [16][0/61], lr: 0.00030	Time 0.479 (0.479)	Data 0.321 (0.321)	Prec@1 100.000 (100.000)	Prec@1 42.188 (42.188)	Prec@1 42.188 (42.188)	Prec@5 100.000 (100.000)	Prec@5 96.875 (96.875)	Prec@5 96.875 (96.875)	Loss 2.3171 (2.3171)   loss_verb 0.0770   loss_noun 1.8182	alpha 1.000  loss_d 0.2380	beta 0.130, 0.130, 0.130  loss_a 2.0013	gamma 0.003000  loss_e_verb 0.2667 loss_e_noun 2.0316	
Train: [17][0/61], lr: 0.00030	Time 0.536 (0.536)	Data 0.418 (0.418)	Prec@1 100.000 (100.000)	Prec@1 28.125 (28.125)	Prec@1 28.125 (28.125)	Prec@5 100.000 (100.000)	Prec@5 95.312 (95.312)	Prec@5 95.312 (95.312)	Loss 2.2173 (2.2173)   loss_verb 0.0342   loss_noun 1.8664	alpha 1.000  loss_d 0.1750	beta 0.138, 0.138, 0.138  loss_a 2.0071	gamma 0.003000  loss_e_verb 0.3563 loss_e_noun 2.0364	
Train: [18][0/61], lr: 0.00030	Time 0.522 (0.522)	Data 0.412 (0.412)	Prec@1 100.000 (100.000)	Prec@1 31.250 (31.250)	Prec@1 31.250 (31.250)	Prec@5 100.000 (100.000)	Prec@5 92.188 (92.188)	Prec@5 92.188 (92.188)	Loss 2.2032 (2.2032)   loss_verb 0.0499   loss_noun 1.8701	alpha 1.000  loss_d 0.1529	beta 0.146, 0.146, 0.146  loss_a 1.9996	gamma 0.003000  loss_e_verb 0.2767 loss_e_noun 2.0314	
Train: [19][0/61], lr: 0.00030	Time 0.547 (0.547)	Data 0.440 (0.440)	Prec@1 100.000 (100.000)	Prec@1 32.812 (32.812)	Prec@1 32.812 (32.812)	Prec@5 100.000 (100.000)	Prec@5 95.312 (95.312)	Prec@5 95.312 (95.312)	Loss 2.2363 (2.2363)   loss_verb 0.0788   loss_noun 1.8854	alpha 1.000  loss_d 0.1566	beta 0.153, 0.153, 0.153  loss_a 1.9997	gamma 0.003000  loss_e_verb 0.4064 loss_e_noun 2.0430	
Train: [20][0/61], lr: 0.00003	Time 0.495 (0.495)	Data 0.408 (0.408)	Prec@1 98.438 (98.438)	Prec@1 35.938 (35.938)	Prec@1 35.938 (35.938)	Prec@5 100.000 (100.000)	Prec@5 93.750 (93.750)	Prec@5 93.750 (93.750)	Loss 2.3584 (2.3584)   loss_verb 0.0976   loss_noun 1.8648	alpha 1.000  loss_d 0.2644	beta 0.161, 0.161, 0.161  loss_a 1.9955	gamma 0.003000  loss_e_verb 0.3093 loss_e_noun 2.0341	
Train: [21][0/61], lr: 0.00003	Time 0.529 (0.529)	Data 0.403 (0.403)	Prec@1 100.000 (100.000)	Prec@1 35.938 (35.938)	Prec@1 35.938 (35.938)	Prec@5 100.000 (100.000)	Prec@5 96.875 (96.875)	Prec@5 96.875 (96.875)	Loss 2.2698 (2.2698)   loss_verb 0.0772   loss_noun 1.8772	alpha 1.000  loss_d 0.1947	beta 0.168, 0.168, 0.168  loss_a 1.9971	gamma 0.003000  loss_e_verb 0.2545 loss_e_noun 2.0402	
Train: [22][0/61], lr: 0.00003	Time 0.527 (0.527)	Data 0.414 (0.414)	Prec@1 100.000 (100.000)	Prec@1 25.000 (25.000)	Prec@1 25.000 (25.000)	Prec@5 100.000 (100.000)	Prec@5 92.188 (92.188)	Prec@5 92.188 (92.188)	Loss 2.3020 (2.3020)   loss_verb 0.0928   loss_noun 1.8948	alpha 1.000  loss_d 0.2050	beta 0.176, 0.176, 0.176  loss_a 2.0034	gamma 0.003000  loss_e_verb 0.2899 loss_e_noun 2.0494	
Train: [23][0/61], lr: 0.00003	Time 0.533 (0.533)	Data 0.424 (0.424)	Prec@1 98.438 (98.438)	Prec@1 40.625 (40.625)	Prec@1 40.625 (40.625)	Prec@5 100.000 (100.000)	Prec@5 98.438 (98.438)	Prec@5 98.438 (98.438)	Loss 2.3575 (2.3575)   loss_verb 0.0682   loss_noun 1.8780	alpha 1.000  loss_d 0.2863	beta 0.183, 0.183, 0.183  loss_a 2.0019	gamma 0.003000  loss_e_verb 0.3375 loss_e_noun 2.0504	
Train: [24][0/61], lr: 0.00003	Time 0.554 (0.554)	Data 0.400 (0.400)	Prec@1 98.438 (98.438)	Prec@1 40.625 (40.625)	Prec@1 40.625 (40.625)	Prec@5 100.000 (100.000)	Prec@5 95.312 (95.312)	Prec@5 95.312 (95.312)	Loss 2.3406 (2.3406)   loss_verb 0.0808   loss_noun 1.8773	alpha 1.000  loss_d 0.2602	beta 0.190, 0.190, 0.190  loss_a 1.9988	gamma 0.003000  loss_e_verb 0.2792 loss_e_noun 2.0507	
Train: [25][0/61], lr: 0.00003	Time 0.545 (0.545)	Data 0.432 (0.432)	Prec@1 100.000 (100.000)	Prec@1 35.938 (35.938)	Prec@1 35.938 (35.938)	Prec@5 100.000 (100.000)	Prec@5 98.438 (98.438)	Prec@5 98.438 (98.438)	Loss 2.5152 (2.5152)   loss_verb 0.0825   loss_noun 1.8592	alpha 1.000  loss_d 0.4336	beta 0.197, 0.197, 0.197  loss_a 1.9984	gamma 0.003000  loss_e_verb 0.2512 loss_e_noun 2.0496	
Train: [26][0/61], lr: 0.00003	Time 0.533 (0.533)	Data 0.410 (0.410)	Prec@1 100.000 (100.000)	Prec@1 25.000 (25.000)	Prec@1 25.000 (25.000)	Prec@5 100.000 (100.000)	Prec@5 98.438 (98.438)	Prec@5 98.438 (98.438)	Loss 2.4434 (2.4434)   loss_verb 0.0599   loss_noun 1.9221	alpha 1.000  loss_d 0.3797	beta 0.204, 0.204, 0.204  loss_a 2.0028	gamma 0.003000  loss_e_verb 0.3316 loss_e_noun 2.0476	
Train: [27][0/61], lr: 0.00003	Time 0.506 (0.506)	Data 0.412 (0.412)	Prec@1 100.000 (100.000)	Prec@1 37.500 (37.500)	Prec@1 37.500 (37.500)	Prec@5 100.000 (100.000)	Prec@5 95.312 (95.312)	Prec@5 95.312 (95.312)	Loss 2.2068 (2.2068)   loss_verb 0.0560   loss_noun 1.8513	alpha 1.000  loss_d 0.1528	beta 0.211, 0.211, 0.211  loss_a 1.9971	gamma 0.003000  loss_e_verb 0.3307 loss_e_noun 2.0469	
Train: [28][0/61], lr: 0.00003	Time 0.507 (0.507)	Data 0.416 (0.416)	Prec@1 100.000 (100.000)	Prec@1 32.812 (32.812)	Prec@1 32.812 (32.812)	Prec@5 100.000 (100.000)	Prec@5 96.875 (96.875)	Prec@5 96.875 (96.875)	Loss 2.2068 (2.2068)   loss_verb 0.0767   loss_noun 1.8542	alpha 1.000  loss_d 0.1269	beta 0.218, 0.218, 0.218  loss_a 2.0024	gamma 0.003000  loss_e_verb 0.2757 loss_e_noun 2.0441	
Train: [29][0/61], lr: 0.00003	Time 0.509 (0.509)	Data 0.417 (0.417)	Prec@1 100.000 (100.000)	Prec@1 40.625 (40.625)	Prec@1 40.625 (40.625)	Prec@5 100.000 (100.000)	Prec@5 92.188 (92.188)	Prec@5 92.188 (92.188)	Loss 2.3327 (2.3327)   loss_verb 0.0824   loss_noun 1.8768	alpha 1.000  loss_d 0.2464	beta 0.224, 0.224, 0.224  loss_a 2.0030	gamma 0.003000  loss_e_verb 0.2738 loss_e_noun 2.0479	
Train: [30][0/61], lr: 0.00003	Time 0.809 (0.809)	Data 0.676 (0.676)	Prec@1 100.000 (100.000)	Prec@1 34.375 (34.375)	Prec@1 34.375 (34.375)	Prec@5 100.000 (100.000)	Prec@5 98.438 (98.438)	Prec@5 98.438 (98.438)	Loss 2.2456 (2.2456)   loss_verb 0.0471   loss_noun 1.8547	alpha 1.000  loss_d 0.1994	beta 0.231, 0.231, 0.231  loss_a 1.9982	gamma 0.003000  loss_e_verb 0.2926 loss_e_noun 2.0453	
total time: 106.836 